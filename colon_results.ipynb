{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from skopt.space import Real\n",
    "\n",
    "import sys\n",
    "sys.path.append('G:/내 드라이브/ensemble kernel')\n",
    "\n",
    "from Kernel_Function_3 import split_data, prepare_response_variable, c_index_kernel_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"colon.csv\")\n",
    "\n",
    "data.replace({'rx':{'Obs':0, 'Lev':1, 'Lev+5FU':2}}, inplace=True)\n",
    "\n",
    "data.rename(columns = {'time' : 'OS', 'status':'Status', 'age' : 'Age', 'sex' : 'Sex'}, inplace = True)\n",
    "\n",
    "df = data.astype({'id':'category',\n",
    "                  'rx':'category',\n",
    "                  'Sex':'category',\n",
    "                  'obstruct':'category',\n",
    "                  'perfor':'category',\n",
    "                  'adhere':'category',\n",
    "                  'node4':'category'})\n",
    "\n",
    "df_drop=df.drop(df.columns[[0,1,2]],axis=1).dropna()\n",
    "\n",
    "df1_drop=df_drop[df_drop['etype'] == 1]\n",
    "df1_drop=df1_drop.drop(df1_drop.columns[[13]],axis=1).dropna()\n",
    "df2_drop=df_drop[df_drop['etype'] == 2]\n",
    "df2_drop=df2_drop.drop(df2_drop.columns[[13]],axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>nodes</th>\n",
       "      <th>Status</th>\n",
       "      <th>differ</th>\n",
       "      <th>extent</th>\n",
       "      <th>surg</th>\n",
       "      <th>OS</th>\n",
       "      <th>rx_1</th>\n",
       "      <th>rx_2</th>\n",
       "      <th>Sex</th>\n",
       "      <th>obstruct_1</th>\n",
       "      <th>perfor_1</th>\n",
       "      <th>adhere_1</th>\n",
       "      <th>node4_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1521</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3087</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>69</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2154</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2072</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  nodes  Status  differ  extent  surg    OS rx_1 rx_2 Sex obstruct_1  \\\n",
       "0      43      5       1       2       3     0  1521    0    1   1          0   \n",
       "2      63      1       0       2       3     0  3087    0    1   1          0   \n",
       "4      71      7       1       2       2     0   963    0    0   0          0   \n",
       "6      66      6       1       2       3     1   293    0    1   0          1   \n",
       "8      69     22       1       2       3     1   659    0    0   1          0   \n",
       "...   ...    ...     ...     ...     ...   ...   ...  ...  ...  ..        ...   \n",
       "1848   71      4       0       2       3     0  1875    0    1   1          0   \n",
       "1850   72      1       0       2       3     0  2154    1    0   0          0   \n",
       "1852   76      1       1       3       3     0  1018    1    0   1          0   \n",
       "1854   48      4       0       2       3     1  2072    0    1   0          1   \n",
       "1856   66      1       0       2       3     0  1820    1    0   0          1   \n",
       "\n",
       "     perfor_1 adhere_1 node4_1  \n",
       "0           0        0       1  \n",
       "2           0        0       0  \n",
       "4           0        1       1  \n",
       "6           0        0       1  \n",
       "8           0        0       1  \n",
       "...       ...      ...     ...  \n",
       "1848        0        1       0  \n",
       "1850        0        0       0  \n",
       "1852        0        1       0  \n",
       "1854        0        0       1  \n",
       "1856        0        0       0  \n",
       "\n",
       "[929 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#onehot encode\n",
    "df_onehot = pd.get_dummies(df2_drop, drop_first=True)\n",
    "\n",
    "columns_to_convert=['Sex_1','adhere_1', 'node4_1', 'obstruct_1', 'perfor_1', 'rx_1', 'rx_2']\n",
    "\n",
    "df_onehot[columns_to_convert] = df_onehot[columns_to_convert].astype('category')\n",
    "df_onehot = df_onehot.rename(columns={'Sex_1' : 'Sex'})\n",
    "\n",
    "df_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=36)\n",
    "\n",
    "param_grid = {'alpha': 2. ** np.arange(-12, 13, 2)}\n",
    "param_space = {'alpha': Real(1e-6, 1e+6, 'log-uniform'),}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of 100 random state numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"random_state_100.txt\", \"r\") as file:\n",
    "    random_state=file.read()\n",
    "    \n",
    "random_state=random_state.split(\"\\n\")\n",
    "random_state=[int(x) for x in random_state if x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining variable results from 100 runs\n",
    "cox_remaining_variable=pd.DataFrame()\n",
    "\n",
    "cox_remaining_variable['variable']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: ConvergenceWarning: Optimization did not converge: Warning: Desired error not necessarily achieved due to precision loss.\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m     test_y \u001b[38;5;241m=\u001b[39m prepare_response_variable(test_target)\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m#Define data -> train, train_y, validation,  test_y\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mc_index_kernel_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mensemble_cox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m     cindex\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m#best_cindex: Store all validation c-index values for each selected variable as a list\u001b[39;00m\n",
      "File \u001b[1;32mg:\\내 드라이브\\ensemble kernel\\Kernel_Function_3.py:148\u001b[0m, in \u001b[0;36mc_index_kernel_type\u001b[1;34m(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords, type)\u001b[0m\n\u001b[0;32m    145\u001b[0m train_c_index \u001b[38;5;241m=\u001b[39m concordance_index_censored(y_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m], y_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOS\u001b[39m\u001b[38;5;124m\"\u001b[39m], train_pred)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Predict on x_test and calculate c_index\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m test_kernel, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mensemble_cox_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m kgcv\u001b[38;5;241m.\u001b[39mpredict(test_kernel)\n\u001b[0;32m    150\u001b[0m test_c_index \u001b[38;5;241m=\u001b[39m concordance_index_censored(y_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m], y_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOS\u001b[39m\u001b[38;5;124m\"\u001b[39m], test_pred)\n",
      "File \u001b[1;32mg:\\내 드라이브\\ensemble kernel\\Kernel_Function_3.py:84\u001b[0m, in \u001b[0;36mensemble_cox_kernel\u001b[1;34m(x1, x2, coef, keywords)\u001b[0m\n\u001b[0;32m     81\u001b[0m nominal_columns \u001b[38;5;241m=\u001b[39m x_drop\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     82\u001b[0m continuous_columns \u001b[38;5;241m=\u001b[39m x_drop\u001b[38;5;241m.\u001b[39mdrop(nominal_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m---> 84\u001b[0m sum_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_o\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontinuous_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_drop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m mat \u001b[38;5;241m=\u001b[39m sum_matrix \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(coef)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mat, coef, remaining_variables\n",
      "File \u001b[1;32mg:\\내 드라이브\\ensemble kernel\\Kernel_Function_3.py:84\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m nominal_columns \u001b[38;5;241m=\u001b[39m x_drop\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     82\u001b[0m continuous_columns \u001b[38;5;241m=\u001b[39m x_drop\u001b[38;5;241m.\u001b[39mdrop(nominal_columns, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m---> 84\u001b[0m sum_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(coef[i] \u001b[38;5;241m*\u001b[39m (\u001b[43mc_o\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m continuous_columns \u001b[38;5;28;01melse\u001b[39;00m nom(x1[i], x2[i])) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m x_drop)\n\u001b[0;32m     85\u001b[0m mat \u001b[38;5;241m=\u001b[39m sum_matrix \u001b[38;5;241m/\u001b[39m \u001b[38;5;28msum\u001b[39m(coef)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mat, coef, remaining_variables\n",
      "File \u001b[1;32mg:\\내 드라이브\\ensemble kernel\\Kernel_Function_3.py:48\u001b[0m, in \u001b[0;36mc_o\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x2)):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x1)):\n\u001b[1;32m---> 48\u001b[0m         x_matrix[i,j] \u001b[38;5;241m=\u001b[39m (d\u001b[38;5;241m-\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mx1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m/\u001b[39md\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_matrix\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    # Separating OS and Status\n",
    "    drop = x_train[['Sex', 'Age', 'OS', 'Status']]\n",
    "    x_train_drop = x_train.drop(columns=['Sex', 'Age', 'OS','Status'])\n",
    "\n",
    "    # Save column names of a DataFrame into a list\n",
    "    columns = x_train_drop.columns\n",
    "\n",
    "    column_groups = []\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        # Generate all combinations of columns taken i+1 at a time\n",
    "        all_column_combinations = list(combinations(columns, i+1))\n",
    "\n",
    "        # Create a DataFrame for each combination\n",
    "        for column_combination in all_column_combinations:\n",
    "            selected_columns = list(column_combination)\n",
    "            sub_train1 = x_train_drop[selected_columns]\n",
    "            sub_train2 = pd.concat([sub_train1, drop], axis=1)\n",
    "            column_groups.append(sub_train2)\n",
    "    \n",
    "    num_groups = 3\n",
    "    best_cindex = []\n",
    "\n",
    "    for i in range(len(column_groups)):\n",
    "        x_groups = []\n",
    "        train = column_groups[i].sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        censored = train[train['Status'] == 0]  # Extract rows with a value of 0\n",
    "        uncensored = train[train['Status'] == 1]  # Extract rows with a value of 1\n",
    "\n",
    "        group_size1 = len(censored) // num_groups\n",
    "        group_size2 = len(uncensored) // num_groups\n",
    "\n",
    "        # Split train data into groups\n",
    "        for i in range(num_groups):\n",
    "                \n",
    "            if i < num_groups - 1:\n",
    "                # Adjusting the censoring ratio\n",
    "                group1 = censored.iloc[i * group_size1:(i + 1) * group_size1]\n",
    "                group2 = uncensored.iloc[i * group_size2:(i + 1) * group_size2]\n",
    "\n",
    "                group = pd.concat([group1, group2], ignore_index=True)\n",
    "            else:\n",
    "                group1 = censored.iloc[i * group_size1:]\n",
    "                group2 = uncensored.iloc[i * group_size2:]\n",
    "\n",
    "                group = pd.concat([group1, group2], ignore_index=True)\n",
    "    \n",
    "            x_groups.append(group)\n",
    "\n",
    "        cindex = []\n",
    "\n",
    "        for i in range(len(x_groups)):\n",
    "\n",
    "            temp = []\n",
    "            for j in range(len(x_groups)):\n",
    "                if i != j:\n",
    "                    temp.append(x_groups[j])\n",
    "            # train = train data(One out of the equally divided segments, excluding one)\n",
    "            train = pd.concat(temp)\n",
    "\n",
    "            # validation = validation data(One of the equally divided segments)\n",
    "            validation = x_groups[i]\n",
    "            \n",
    "            train_target = train[['Status','OS']]\n",
    "            test_target = validation[['Status','OS']]\n",
    "\n",
    "            train_y = prepare_response_variable(train_target)\n",
    "            test_y = prepare_response_variable(test_target)\n",
    "            #Define data -> train, train_y, validation,  test_y\n",
    "\n",
    "            result = c_index_kernel_type(train, train_y, validation, test_y, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = 'ensemble_cox')\n",
    "            cindex.append(result[1])\n",
    "\n",
    "        #best_cindex: Store all validation c-index values for each selected variable as a list\n",
    "        best_cindex.append(np.mean(cindex))\n",
    "\n",
    "    #max_num: Index number of the best c-index in the list\n",
    "    max_num = best_cindex.index(max(best_cindex))\n",
    "\n",
    "    #train_column: Selected variables for the best c-index\n",
    "    train_column = column_groups[max_num].columns\n",
    "    \n",
    "    cox_remaining_variable = cox_remaining_variable.append({\"variable\": list(train_column)}, ignore_index = True)\n",
    "\n",
    "cox_remaining_variable.to_csv(\"colon_cox_remaining_variables.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C-index by Kernel type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_results=pd.DataFrame()\n",
    "\n",
    "linear_results['train_C_index']=[]\n",
    "linear_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'linear'\n",
    "\n",
    "for i in range(100):\n",
    "    variables = eval(pd.read_csv(\"ensemble_cox_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    variables.append('Status')\n",
    "    variables.append('OS')\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    linear_results = linear_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "linear_results.to_csv(\"colon_linear_repetition.csv\", index = False, encoding = 'cp949')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clinical Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_results=pd.DataFrame()\n",
    "\n",
    "clinical_results['train_C_index']=[]\n",
    "clinical_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'clinical'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"colon_cox_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    variables.append('Status')\n",
    "    variables.append('OS')\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    clinical_results = clinical_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "clinical_results.to_csv(\"colon_clinical_repetition.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensemble Cox kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_cox_results=pd.DataFrame()\n",
    "\n",
    "ensemble_cox_results['train_C_index']=[]\n",
    "ensemble_cox_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ensemble_cox'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"colon_cox_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    variables.append('Status')\n",
    "    variables.append('OS')\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    ensemble_aft_results = ensemble_aft_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "ensemble_aft_results.to_csv(\"colon_cox_repetition.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensemble AFT Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_aft_results=pd.DataFrame()\n",
    "\n",
    "ensemble_aft_results['train_C_index']=[]\n",
    "ensemble_aft_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ensemble_aft'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"colon_cox_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    variables.append('Status')\n",
    "    variables.append('OS')\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    ensemble_aft_results = ensemble_aft_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "ensemble_aft_results.to_csv(\"colon_aft_repetition.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_results = pd.read_csv('colon_linear_repetition.csv')\n",
    "clinical_results = pd.read_csv('colon_clinical_repetition.csv')\n",
    "ensemble_cox_results = pd.read_csv('colon_cox_repetition.csv')\n",
    "ensemble_aft_results = pd.read_csv('colon_aft_repetition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count of selections for each remaining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_variables_all=[]\n",
    "for i in range(0,100):\n",
    "    remaining_variables_all+=eval(pd.read_csv(\"colon_cox_repetition.csv\")['remaining_variables'][i])\n",
    "\n",
    "element_counts = {}\n",
    "\n",
    "for element in remaining_variables_all:\n",
    "    if element in element_counts:\n",
    "        element_counts[element] += 1\n",
    "    else:\n",
    "        element_counts[element] = 1\n",
    "\n",
    "print(element_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The value of C-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(np.mean(linear_results['train_C_index']),4))\n",
    "print(round(np.std(linear_results['train_C_index']),4))\n",
    "print(round(np.mean(linear_results['test_C_index']),4))\n",
    "print(round(np.std(linear_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(np.mean(clinical_results['train_C_index']),4))\n",
    "print(round(np.std(clinical_results['train_C_index']),4))\n",
    "print(round(np.mean(clinical_results['test_C_index']),4))\n",
    "print(round(np.std(clinical_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(np.mean(ensemble_cox_results['train_C_index']),4))\n",
    "print(round(np.std(ensemble_cox_results['train_C_index']),4))\n",
    "print(round(np.mean(ensemble_cox_results['test_C_index']),4))\n",
    "print(round(np.std(ensemble_cox_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(np.mean(ensemble_aft_results['train_C_index']),4))\n",
    "print(round(np.std(ensemble_aft_results['train_C_index']),4))\n",
    "print(round(np.mean(ensemble_aft_results['test_C_index']),4))\n",
    "print(round(np.std(ensemble_aft_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining variable results from 100 runs\n",
    "aft_remaining_variable=pd.DataFrame()\n",
    "\n",
    "aft_remaining_variable['variable']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### C-index results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    # Separating OS and Status\n",
    "    drop = x_train[['Sex', 'Age', 'OS','Status']]\n",
    "    x_train_drop = x_train.drop(columns=['Sex', 'Age', 'OS','Status'])\n",
    "\n",
    "    # Save column names of a DataFrame into a list\n",
    "    columns = x_train_drop.columns\n",
    "\n",
    "    column_groups = []\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        # Generate all combinations of columns taken i+1 at a time\n",
    "        all_column_combinations = list(combinations(columns, i+1))\n",
    "\n",
    "        # Create a DataFrame for each combination\n",
    "        for column_combination in all_column_combinations:\n",
    "            selected_columns = list(column_combination)\n",
    "            sub_train1 = x_train_drop[selected_columns]\n",
    "            sub_train2 = pd.concat([sub_train1, drop], axis=1)\n",
    "            column_groups.append(sub_train2)\n",
    "    \n",
    "    num_groups = 3\n",
    "    best_cindex = []\n",
    "\n",
    "    for i in range(len(column_groups)):\n",
    "        x_groups = []\n",
    "        train = column_groups[i].sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        censored = train[train['Status'] == 0]  # Extract rows with a value of 0\n",
    "        uncensored = train[train['Status'] == 1]  # Extract rows with a value of 1\n",
    "\n",
    "        group_size1 = len(censored) // num_groups\n",
    "        group_size2 = len(uncensored) // num_groups\n",
    "\n",
    "        # Splitting the train data into groups\n",
    "        for i in range(num_groups):\n",
    "\n",
    "            if i < num_groups - 1:\n",
    "                # Adjusting the censoring ratio\n",
    "                group1 = censored.iloc[i * group_size1:(i + 1) * group_size1]\n",
    "                group2 = uncensored.iloc[i * group_size2:(i + 1) * group_size2]\n",
    "\n",
    "                group = pd.concat([group1, group2], ignore_index=True)\n",
    "            else:\n",
    "                group1 = censored.iloc[i * group_size1:]\n",
    "                group2 = uncensored.iloc[i * group_size2:]\n",
    "\n",
    "                group = pd.concat([group1, group2], ignore_index=True)\n",
    "    \n",
    "            x_groups.append(group)\n",
    "\n",
    "        cindex = []\n",
    "\n",
    "        for i in range(len(x_groups)):\n",
    "\n",
    "            temp = []\n",
    "            for j in range(len(x_groups)):\n",
    "                if i != j:\n",
    "                    temp.append(x_groups[j])\n",
    "            #train = train data(One out of the equally divided segments, excluding one)\n",
    "            train=pd.concat(temp)\n",
    "\n",
    "            #validation = validation data(One of the equally divided segments)\n",
    "            validation = x_groups[i]\n",
    "            \n",
    "            train_target=train[['Status','OS']]\n",
    "            test_target=validation[['Status','OS']]\n",
    "\n",
    "            train_y=prepare_response_variable(train_target)\n",
    "            test_y=prepare_response_variable(test_target)\n",
    "            #Define data -> train, train_y, validation,  test_y\n",
    "\n",
    "            result = c_index_kernel_type(train, train_y, validation, test_y, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = 'ensemble_aft')\n",
    "            cindex.append(result[1])\n",
    "\n",
    "        #best_cindex: Store all validation c-index values for each selected variable as a list\n",
    "        best_cindex.append(np.mean(cindex))\n",
    "\n",
    "    #max_num: Index number of the best c-index in the list\n",
    "    max_num = best_cindex.index(max(best_cindex))\n",
    "\n",
    "    #train_column: Selected variables for the best c-index\n",
    "    train_column = column_groups[max_num].columns\n",
    "    \n",
    "    aft_remaining_variable = aft_remaining_variable.append({\"variable\": list(train_column)}, ignore_index = True)\n",
    "\n",
    "aft_remaining_variable.to_csv(\"colon_aft_remaining_variables.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check results by Kernel type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_results=pd.DataFrame()\n",
    "\n",
    "linear_results['train_C_index']=[]\n",
    "linear_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'linear'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"colon_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    linear_results = linear_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "linear_results.to_csv(\"colon_aft_linear.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clinical Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_results=pd.DataFrame()\n",
    "\n",
    "clinical_results['train_C_index']=[]\n",
    "clinical_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'clinical'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"colon_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    clinical_results = clinical_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "clinical_results.to_csv(\"colon_aft_clinical.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensemble Cox Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_cox_results=pd.DataFrame()\n",
    "\n",
    "ensemble_cox_results['train_C_index']=[]\n",
    "ensemble_cox_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ensemble_cox'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"colon_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    ensemble_cox_results = ensemble_cox_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "ensemble_cox_results.to_csv(\"colon_aft_cox.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensemble AFT Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_aft_results=pd.DataFrame()\n",
    "\n",
    "ensemble_aft_results['train_C_index']=[]\n",
    "ensemble_aft_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ensemble_aft'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = remaining_variable[i]\n",
    "    variables = eval(pd.read_csv(\"colon_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    ensemble_aft_results = ensemble_aft_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "ensemble_aft_results.to_csv(\"colon_aft_aft.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_results = pd.read_csv('colon_aft_linear.csv')\n",
    "clinical_results = pd.read_csv('colon_aft_clinical.csv')\n",
    "ensemble_cox_results = pd.read_csv('colon_aft_cox.csv')\n",
    "ensemble_aft_results = pd.read_csv('colon_aft_aft.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count of selections for each remaining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_variables_all=[]\n",
    "for i in range(0,100):\n",
    "    remaining_variables_all += eval(pd.read_csv(\"colon_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "element_counts = {}\n",
    "\n",
    "for element in remaining_variables_all:\n",
    "    if element in element_counts:\n",
    "        element_counts[element] += 1\n",
    "    else:\n",
    "        element_counts[element] = 1\n",
    "\n",
    "print(element_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The value of the C-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(np.mean(linear_results['train_C_index']),4))\n",
    "print(round(np.std(linear_results['train_C_index']),4))\n",
    "print(round(np.mean(linear_results['test_C_index']),4))\n",
    "print(round(np.std(linear_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(np.mean(clinical_results['train_C_index']),4))\n",
    "print(round(np.std(clinical_results['train_C_index']),4))\n",
    "print(round(np.mean(clinical_results['test_C_index']),4))\n",
    "print(round(np.std(clinical_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(np.mean(ensemble_cox_results['train_C_index']),4))\n",
    "print(round(np.std(ensemble_cox_results['train_C_index']),4))\n",
    "print(round(np.mean(ensemble_cox_results['test_C_index']),4))\n",
    "print(round(np.std(ensemble_cox_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(np.mean(ensemble_aft_results['train_C_index']),4))\n",
    "print(round(np.std(ensemble_aft_results['train_C_index']),4))\n",
    "print(round(np.mean(ensemble_aft_results['test_C_index']),4))\n",
    "print(round(np.std(ensemble_aft_results['test_C_index']),4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
