{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from skopt.space import Real\n",
    "\n",
    "import sys\n",
    "sys.path.append('G:/내 드라이브/ensemble kernel')\n",
    "\n",
    "from Kernel_Function_3 import split_data, prepare_response_variable, c_index_kernel_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OS</th>\n",
       "      <th>Status</th>\n",
       "      <th>karno</th>\n",
       "      <th>diagtime</th>\n",
       "      <th>Age</th>\n",
       "      <th>trt_2</th>\n",
       "      <th>celltype_1</th>\n",
       "      <th>celltype_2</th>\n",
       "      <th>celltype_0</th>\n",
       "      <th>prior_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>411</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>228</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>378</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      OS  Status  karno  diagtime  Age trt_2 celltype_1 celltype_2 celltype_0  \\\n",
       "0     72       1     60         7   69     0          0          0          1   \n",
       "1    411       1     70         5   64     0          0          0          1   \n",
       "2    228       1     60         3   38     0          0          0          1   \n",
       "3    126       1     60         9   63     0          0          0          1   \n",
       "4    118       1     70        11   65     0          0          0          1   \n",
       "..   ...     ...    ...       ...  ...   ...        ...        ...        ...   \n",
       "132  133       1     75         1   65     1          1          0          0   \n",
       "133  111       1     60         5   64     1          1          0          0   \n",
       "134  231       1     70        18   67     1          1          0          0   \n",
       "135  378       1     80         4   65     1          1          0          0   \n",
       "136   49       1     30         3   37     1          1          0          0   \n",
       "\n",
       "    prior_10  \n",
       "0          0  \n",
       "1          1  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "..       ...  \n",
       "132        0  \n",
       "133        0  \n",
       "134        1  \n",
       "135        0  \n",
       "136        0  \n",
       "\n",
       "[137 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"veteran_data.csv\")\n",
    "\n",
    "df = data.drop(['Unnamed: 0'], axis=1)\n",
    "df = df.astype({'trt' : 'category', 'celltype' : 'category', 'prior' : 'category'})\n",
    "df.replace({'celltype' : {'squamous' : 0, 'large' : 1, 'smallcell' : 2, 'adeno' : 3}}, inplace = True)\n",
    "\n",
    "df = df.rename(columns={'age':'Age',\n",
    "                        'time':'OS',\n",
    "                        'status':'Status'})\n",
    "\n",
    "# onehot encode\n",
    "df_onehot = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "columns_to_convert=['celltype_1', 'celltype_2','celltype_0', 'prior_10', 'trt_2']\n",
    "\n",
    "df_onehot[columns_to_convert] = df_onehot[columns_to_convert].astype('category')\n",
    "\n",
    "df_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=[0, 1], ordered=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot['trt_2'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KFold Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold setting\n",
    "cv=KFold(n_splits = 5, shuffle=True, random_state=36)\n",
    "\n",
    "param_space = {\n",
    "    'alpha': Real(1e-6, 1e+6, 'log-uniform'),\n",
    "}\n",
    "param_grid = {'alpha': 2. ** np.arange(-12, 13, 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting 100 random state numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "with open(\"random_state_100.txt\", \"r\") as file:\n",
    "    random_state=file.read()\n",
    "    \n",
    "random_state=random_state.split(\"\\n\")\n",
    "random_state=[int(x) for x in random_state if x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining variable results from 100 runs\n",
    "cox_remaining_variable=pd.DataFrame()\n",
    "\n",
    "cox_remaining_variable['variable']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C-index results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: ConvergenceWarning: Optimization did not converge: Warning: Desired error not necessarily achieved due to precision loss.\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "c:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: ConvergenceWarning: Optimization did not converge: Warning: Desired error not necessarily achieved due to precision loss.\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m     test_y\u001b[38;5;241m=\u001b[39mprepare_response_variable(test_target)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;66;03m#Define data -> train, train_y, validation,  test_y\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mc_index_kernel_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeywords\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mensemble_cox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     cindex\u001b[38;5;241m.\u001b[39mappend(result[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m#best_cindex: Store all validation c-index values for each selected variable as a list\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stat\\Desktop\\Ensemble-kernel\\Kernel_Function_3.py:141\u001b[0m, in \u001b[0;36mc_index_kernel_type\u001b[1;34m(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords, type)\u001b[0m\n\u001b[0;32m    138\u001b[0m kgcv \u001b[38;5;241m=\u001b[39m GridSearchCV(kssvm, param_grid, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cv\u001b[38;5;241m=\u001b[39mcv)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# Fit model\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m \u001b[43mkgcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_kernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Predict on x_train and calculate c_index\u001b[39;00m\n\u001b[0;32m    144\u001b[0m train_pred \u001b[38;5;241m=\u001b[39m kgcv\u001b[38;5;241m.\u001b[39mpredict(train_kernel)\n",
      "File \u001b[1;32mc:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:435\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\Users\\stat\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    # Separating OS and Status\n",
    "    drop = x_train[['Age', 'OS','Status']]\n",
    "    x_train_drop = x_train.drop(columns=['Age', 'OS','Status'])\n",
    "\n",
    "    # Save column names of a DataFrame into a list\n",
    "    columns = x_train_drop.columns\n",
    "\n",
    "    column_groups = []\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        # Generate all combinations of columns taken i+1 at a time\n",
    "        all_column_combinations = list(combinations(columns, i+1))\n",
    "\n",
    "        # Create a DataFrame for each combination\n",
    "        for column_combination in all_column_combinations:\n",
    "            selected_columns = list(column_combination)\n",
    "            sub_train1 = x_train_drop[selected_columns]\n",
    "            sub_train2 = pd.concat([sub_train1, drop], axis=1)\n",
    "            column_groups.append(sub_train2)\n",
    "    \n",
    "    num_groups = 3\n",
    "    best_cindex = []\n",
    "\n",
    "    for i in range(len(column_groups)):\n",
    "        x_groups = []\n",
    "        train = column_groups[i].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Splitting the train data into groups\n",
    "        for i in range(num_groups):\n",
    "            censored = train[train['Status'] == 0]  # Extract rows with a value of 0\n",
    "            uncensored = train[train['Status'] == 1]  # Extract rows with a value of 1\n",
    "\n",
    "            group_size1 = len(censored) // num_groups\n",
    "            group_size2 = len(uncensored) // num_groups\n",
    "\n",
    "            if i < num_groups - 1:\n",
    "                # Adjusting the censoring ratio\n",
    "                group1 = censored.iloc[i * group_size1:(i + 1) * group_size1]\n",
    "                group2 = uncensored.iloc[i * group_size2:(i + 1) * group_size2]\n",
    "\n",
    "                group = pd.concat([group1, group2], ignore_index=True)\n",
    "            else:\n",
    "                group1 = censored.iloc[i * group_size1:]\n",
    "                group2 = uncensored.iloc[i * group_size2:]\n",
    "\n",
    "                group = pd.concat([group1, group2], ignore_index=True)\n",
    "    \n",
    "            x_groups.append(group)\n",
    "\n",
    "        cindex = []\n",
    "\n",
    "        for i in range(len(x_groups)):\n",
    "\n",
    "            temp = []\n",
    "            for j in range(len(x_groups)):\n",
    "                if i != j:\n",
    "                    temp.append(x_groups[j])\n",
    "            #train = train data(One out of the equally divided segments, excluding one)\n",
    "            train=pd.concat(temp)\n",
    "\n",
    "            #validation = validation data(One of the equally divided segments)\n",
    "            validation = x_groups[i]\n",
    "            \n",
    "            train_target=train[['Status','OS']]\n",
    "            test_target=validation[['Status','OS']]\n",
    "\n",
    "            train_y=prepare_response_variable(train_target)\n",
    "            test_y=prepare_response_variable(test_target)\n",
    "            #Define data -> train, train_y, validation,  test_y\n",
    "\n",
    "            result = c_index_kernel_type(train, train_y, validation, test_y, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = 'ensemble_cox')\n",
    "            cindex.append(result[1])\n",
    "\n",
    "        #best_cindex: Store all validation c-index values for each selected variable as a list\n",
    "        best_cindex.append(np.mean(cindex))\n",
    "\n",
    "    #max_num: Index number of the best c-index in the list\n",
    "    max_num = best_cindex.index(max(best_cindex))\n",
    "\n",
    "    #train_column: Selected variables for the best c-index\n",
    "    train_column = column_groups[max_num].columns\n",
    "    \n",
    "    cox_remaining_variable = cox_remaining_variable.append({\"variable\": list(train_column)}, ignore_index = True)\n",
    "\n",
    "cox_remaining_variable.to_csv(\"veteran_cox_remaining_variables.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results by Kernel type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_results=pd.DataFrame()\n",
    "\n",
    "linear_results['train_C_index']=[]\n",
    "linear_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'linear'\n",
    "\n",
    "for i in range(100):\n",
    "    variables = eval(pd.read_csv(\"veteran_cox_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    variables.append('Status')\n",
    "    variables.append('OS')\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    linear_results = linear_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "linear_results.to_csv(\"veteran_linear_repetition.csv\", index = False, encoding = 'cp949')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clinical Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_results=pd.DataFrame()\n",
    "\n",
    "clinical_results['train_C_index']=[]\n",
    "clinical_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'clinical'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"veteran_cox_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    variables.append('Status')\n",
    "    variables.append('OS')\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    clinical_results = clinical_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "clinical_results.to_csv(\"veteran_clinical_repetition.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Cox Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_cox_results=pd.DataFrame()\n",
    "\n",
    "ensemble_cox_results['train_C_index']=[]\n",
    "ensemble_cox_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ensemble_cox'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"veteran_cox_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    variables.append('Status')\n",
    "    variables.append('OS')\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    ensemble_aft_results = ensemble_aft_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "ensemble_aft_results.to_csv(\"veteran_cox_repetition.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble AFT Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_aft_results=pd.DataFrame()\n",
    "\n",
    "ensemble_aft_results['train_C_index']=[]\n",
    "ensemble_aft_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ensemble_aft'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"veteran_cox_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    variables.append('Status')\n",
    "    variables.append('OS')\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    ensemble_aft_results = ensemble_aft_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "ensemble_aft_results.to_csv(\"veteran_aft_repetition.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_results = pd.read_csv('veteran_linear_repetition.csv')\n",
    "clinical_results = pd.read_csv('veteran_clinical_repetition.csv')\n",
    "ensemble_cox_results = pd.read_csv('veteran_cox_repetition.csv')\n",
    "ensemble_aft_results = pd.read_csv('veteran_aft_repetition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count of selections for each remaining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'karno': 100, 'celltype_2': 43, 'trt_2': 35, 'Age': 100, 'diagtime': 43, 'celltype_1': 69, 'celltype_0': 59, 'prior_10': 32}\n"
     ]
    }
   ],
   "source": [
    "remaining_variables_all=[]\n",
    "for i in range(0,100):\n",
    "    remaining_variables_all+=eval(pd.read_csv(\"veteran_cox_repetition.csv\")['remaining_variables'][i])\n",
    "\n",
    "element_counts = {}\n",
    "\n",
    "for element in remaining_variables_all:\n",
    "    if element in element_counts:\n",
    "        element_counts[element] += 1\n",
    "    else:\n",
    "        element_counts[element] = 1\n",
    "\n",
    "print(element_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the C-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7149\n",
      "0.0169\n",
      "0.7008\n",
      "0.035\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(linear_results['train_C_index']),4))\n",
    "print(round(np.std(linear_results['train_C_index']),4))\n",
    "print(round(np.mean(linear_results['test_C_index']),4))\n",
    "print(round(np.std(linear_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7605\n",
      "0.0284\n",
      "0.6942\n",
      "0.0371\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(clinical_results['train_C_index']),4))\n",
    "print(round(np.std(clinical_results['train_C_index']),4))\n",
    "print(round(np.mean(clinical_results['test_C_index']),4))\n",
    "print(round(np.std(clinical_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7588\n",
      "0.0255\n",
      "0.6949\n",
      "0.0371\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(ensemble_cox_results['train_C_index']),4))\n",
    "print(round(np.std(ensemble_cox_results['train_C_index']),4))\n",
    "print(round(np.mean(ensemble_cox_results['test_C_index']),4))\n",
    "print(round(np.std(ensemble_cox_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7582\n",
      "0.0254\n",
      "0.6945\n",
      "0.0368\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(ensemble_aft_results['train_C_index']),4))\n",
    "print(round(np.std(ensemble_aft_results['train_C_index']),4))\n",
    "print(round(np.mean(ensemble_aft_results['test_C_index']),4))\n",
    "print(round(np.std(ensemble_aft_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining variable results from 100 runs\n",
    "aft_remaining_variable=pd.DataFrame()\n",
    "\n",
    "aft_remaining_variable['variable']=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C-index results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    # Separating OS and Status\n",
    "    drop = x_train[['Age', 'OS','Status']]\n",
    "    x_train_drop = x_train.drop(columns=['Age', 'OS','Status'])\n",
    "\n",
    "    # Save column names of a DataFrame into a list\n",
    "    columns = x_train_drop.columns\n",
    "\n",
    "    column_groups = []\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        # Generate all combinations of columns taken i+1 at a time\n",
    "        all_column_combinations = list(combinations(columns, i+1))\n",
    "\n",
    "        # Create a DataFrame for each combination\n",
    "        for column_combination in all_column_combinations:\n",
    "            selected_columns = list(column_combination)\n",
    "            sub_train1 = x_train_drop[selected_columns]\n",
    "            sub_train2 = pd.concat([sub_train1, drop], axis=1)\n",
    "            column_groups.append(sub_train2)\n",
    "    \n",
    "    num_groups = 3\n",
    "    best_cindex = []\n",
    "\n",
    "    for i in range(len(column_groups)):\n",
    "        x_groups = []\n",
    "        train = column_groups[i].sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        # Splitting the train data into groups\n",
    "        for i in range(num_groups):\n",
    "            censored = train[train['Status'] == 0]  # Extract rows with a value of 0\n",
    "            uncensored = train[train['Status'] == 1]  # Extract rows with a value of 1\n",
    "\n",
    "            group_size1 = len(censored) // num_groups\n",
    "            group_size2 = len(uncensored) // num_groups\n",
    "\n",
    "            if i < num_groups - 1:\n",
    "                # Adjusting the censoring ratio\n",
    "                group1 = censored.iloc[i * group_size1:(i + 1) * group_size1]\n",
    "                group2 = uncensored.iloc[i * group_size2:(i + 1) * group_size2]\n",
    "\n",
    "                group = pd.concat([group1, group2], ignore_index=True)\n",
    "            else:\n",
    "                group1 = censored.iloc[i * group_size1:]\n",
    "                group2 = uncensored.iloc[i * group_size2:]\n",
    "\n",
    "                group = pd.concat([group1, group2], ignore_index=True)\n",
    "    \n",
    "            x_groups.append(group)\n",
    "\n",
    "        cindex = []\n",
    "\n",
    "        for i in range(len(x_groups)):\n",
    "\n",
    "            temp = []\n",
    "            for j in range(len(x_groups)):\n",
    "                if i != j:\n",
    "                    temp.append(x_groups[j])\n",
    "            #train = train data(One out of the equally divided segments, excluding one)\n",
    "            train=pd.concat(temp)\n",
    "\n",
    "            #validation = validation data(One of the equally divided segments)\n",
    "            validation = x_groups[i]\n",
    "            \n",
    "            train_target=train[['Status','OS']]\n",
    "            test_target=validation[['Status','OS']]\n",
    "\n",
    "            train_y=prepare_response_variable(train_target)\n",
    "            test_y=prepare_response_variable(test_target)\n",
    "            #Define data -> train, train_y, validation,  test_y\n",
    "\n",
    "            result = c_index_kernel_type(train, train_y, validation, test_y, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = 'ensemble_aft')\n",
    "            cindex.append(result[1])\n",
    "\n",
    "        #best_cindex: Store all validation c-index values for each selected variable as a list\n",
    "        best_cindex.append(np.mean(cindex))\n",
    "\n",
    "    #max_num: Index number of the best c-index in the list\n",
    "    max_num = best_cindex.index(max(best_cindex))\n",
    "\n",
    "    #train_column: Selected variables for the best c-index\n",
    "    train_column = column_groups[max_num].columns\n",
    "    \n",
    "    aft_remaining_variable = aft_remaining_variable.append({\"variable\": list(train_column)}, ignore_index = True)\n",
    "\n",
    "aft_remaining_variable.to_csv(\"veteran_aft_remaining_variables.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results by Kernel type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_results=pd.DataFrame()\n",
    "\n",
    "linear_results['train_C_index']=[]\n",
    "linear_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'linear'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"veteran_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    linear_results = linear_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "linear_results.to_csv(\"veteran_aft_linear.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clinical Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_results=pd.DataFrame()\n",
    "\n",
    "clinical_results['train_C_index']=[]\n",
    "clinical_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'clinical'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"veteran_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    clinical_results = clinical_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "clinical_results.to_csv(\"veteran_aft_clinical.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble Cox Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_cox_results=pd.DataFrame()\n",
    "\n",
    "ensemble_cox_results['train_C_index']=[]\n",
    "ensemble_cox_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ensemble_cox'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = all_results['remaining_variables'][i]\n",
    "    variables = eval(pd.read_csv(\"veteran_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    ensemble_cox_results = ensemble_cox_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "ensemble_cox_results.to_csv(\"veteran_aft_cox.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble AFT Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_aft_results=pd.DataFrame()\n",
    "\n",
    "ensemble_aft_results['train_C_index']=[]\n",
    "ensemble_aft_results['test_C_index']=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'ensemble_aft'\n",
    "\n",
    "for i in range(100):\n",
    "    #variables = remaining_variable[i]\n",
    "    variables = eval(pd.read_csv(\"veteran_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "    df_onehot_re = df_onehot[variables]\n",
    "    \n",
    "    x_train, x_test, target_train, target_test = split_data(df_onehot_re, randomState = random_state[i])\n",
    "\n",
    "    y_train = prepare_response_variable(target_train)\n",
    "    y_test = prepare_response_variable(target_test)\n",
    "\n",
    "    results = c_index_kernel_type(x_train, y_train, x_test, y_test, param_grid, param_space, cv, keywords = ['Age', 'Sex'], type = kernel_type)\n",
    "    \n",
    "    ensemble_aft_results = ensemble_aft_results.append({\"train_C_index\":results[0],\"test_C_index\":results[1]}, ignore_index=True)\n",
    "\n",
    "ensemble_aft_results.to_csv(\"veteran_aft_aft.csv\", index = False, encoding = 'cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_results = pd.read_csv('veteran_aft_linear.csv')\n",
    "clinical_results = pd.read_csv('veteran_aft_clinical.csv')\n",
    "ensemble_cox_results = pd.read_csv('veteran_aft_cox.csv')\n",
    "ensemble_aft_results = pd.read_csv('veteran_aft_aft.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count of selections for each remaining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'karno': 100, 'diagtime': 44, 'celltype_1': 78, 'prior_10': 39, 'Age': 100, 'OS': 100, 'Status': 100, 'celltype_2': 52, 'celltype_0': 62, 'trt_2': 46}\n"
     ]
    }
   ],
   "source": [
    "remaining_variables_all=[]\n",
    "for i in range(0,100):\n",
    "    remaining_variables_all += eval(pd.read_csv(\"veteran_aft_remaining_variables.csv\")['variable'][i])\n",
    "\n",
    "element_counts = {}\n",
    "\n",
    "for element in remaining_variables_all:\n",
    "    if element in element_counts:\n",
    "        element_counts[element] += 1\n",
    "    else:\n",
    "        element_counts[element] = 1\n",
    "\n",
    "print(element_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of the C-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7146\n",
      "0.0173\n",
      "0.7002\n",
      "0.0342\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(linear_results['train_C_index']),4))\n",
    "print(round(np.std(linear_results['train_C_index']),4))\n",
    "print(round(np.mean(linear_results['test_C_index']),4))\n",
    "print(round(np.std(linear_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7607\n",
      "0.0245\n",
      "0.6965\n",
      "0.037\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(clinical_results['train_C_index']),4))\n",
    "print(round(np.std(clinical_results['train_C_index']),4))\n",
    "print(round(np.mean(clinical_results['test_C_index']),4))\n",
    "print(round(np.std(clinical_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7599\n",
      "0.0228\n",
      "0.6961\n",
      "0.0392\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(ensemble_cox_results['train_C_index']),4))\n",
    "print(round(np.std(ensemble_cox_results['train_C_index']),4))\n",
    "print(round(np.mean(ensemble_cox_results['test_C_index']),4))\n",
    "print(round(np.std(ensemble_cox_results['test_C_index']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7592\n",
      "0.025\n",
      "0.6954\n",
      "0.0388\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(ensemble_aft_results['train_C_index']),4))\n",
    "print(round(np.std(ensemble_aft_results['train_C_index']),4))\n",
    "print(round(np.mean(ensemble_aft_results['test_C_index']),4))\n",
    "print(round(np.std(ensemble_aft_results['test_C_index']),4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
