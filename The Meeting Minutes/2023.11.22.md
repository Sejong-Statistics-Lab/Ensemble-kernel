# 2023.11.22

## <Collaborative Work>

### ğŸŒŸCollaborative

## <Personal Work>

### â›„Nayeon

- Ensemble Kernel cross validation
    
    ì½”ë“œ í™•ì¸ì€ Ensemble-Kernel repositories
    
    - repetition 100ë²ˆ ì‹¤í–‰
        - ì´ì „ì—” ê²°ê³¼ë¥¼ ë‚´ëŠ” ê³¼ì •ê¹Œì§€ ëª¨ë‘ í¬í•¨í–ˆì§€ë§Œ, remaining variables ì¶”ì¶œê¹Œì§€ í•˜ê³  ì €ì¥í›„ ê²°ê³¼ í™•ì¸ì€ ë¶„ë¦¬í•´ì„œ í™•ì¸í•˜ëŠ” ê²ƒìœ¼ë¡œ ìˆ˜ì •
        - C_index_fastKernelSurvivalSVM(coef_drop=None)
            - *coef_drop({â€™linearâ€™, â€˜clinicalâ€™, â€˜ensemble_aftâ€™, â€˜ensemble_coxâ€™} or callable, default: â€˜ensemble_coxâ€™).*
            - 
        
        ```python
        #all_results : 100ë²ˆ ëŒë¦° ëª¨ë“  ê²°ê³¼ë¥¼ ì €ì¥í•´ë‘” dataframe
        all_results=pd.DataFrame()
        
        all_results['train_C_index']=[]
        all_results['test_C_index']=[]
        all_results['remaining_variables']=[]
        
        import random
        
        with open("random_state_100.txt", "r") as file:
            random_state=file.read()
            
        random_state=random_state.split("\n")
        random_state=[int(x) for x in random_state if x]
        
        #ìµœì¢… C-index ê²°ê³¼ í™•ì¸
        for i in range(100):
            x_train, x_test, target_train, target_test = split_data(df_onehot, randomState = random_state[i])
        
            y_train = prepare_response_variable(target_train)
            y_test = prepare_response_variable(target_test)
        
            #os, status ë¶„ë¦¬
            drop = x_train[['Age','OS','Status']]
            x_train_drop = x_train.drop(columns=['Age','OS','Status'])
        
            # ë°ì´í„°í”„ë ˆì„ì˜ ì—´ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
            columns = x_train_drop.columns
        
            column_groups = []
        
            for i in range(len(columns)):
                # i+1ê°œì”© ì„ íƒí•œ ëª¨ë“  ì—´ ì¡°í•©ì„ ìƒì„±
                all_column_combinations = list(combinations(columns, i+1))
        
                # ê° ì¡°í•©ì— ëŒ€í•œ ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±í•˜ê³  ì¶œë ¥
                for column_combination in all_column_combinations:
                    selected_columns = list(column_combination)
                    sub_train1 = x_train_drop[selected_columns]
                    sub_train2 = pd.concat([sub_train1, drop], axis=1)
                    column_groups.append(sub_train2)
            
            num_groups = 3
            best_cindex = []
        
            for i in range(len(column_groups)):
                x_groups = []
                train = column_groups[i].sample(frac=1).reset_index(drop=True)
        
                # train dataë¥¼ ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
                for i in range(num_groups):
                    censored = train[train['Status'] == 0]  # 0ì¸ í–‰ë§Œ ì¶”ì¶œ
                    uncensored = train[train['Status'] == 1]  # 1ì¸ í–‰ë§Œ ì¶”ì¶œ
        
                    group_size1 = len(censored) // num_groups
                    group_size2 = len(uncensored) // num_groups
        
                    if i < num_groups - 1:
                        #censoring ë¹„ìœ¨ ë§ì¶”ê¸°
                        group1 = censored.iloc[i * group_size1:(i + 1) * group_size1]
                        group2 = uncensored.iloc[i * group_size2:(i + 1) * group_size2]
        
                        group = pd.concat([group1, group2], ignore_index=True)
                    else:
                        group1 = censored.iloc[i * group_size1:]
                        group2 = uncensored.iloc[i * group_size2:]
        
                        group = pd.concat([group1, group2], ignore_index=True)
            
                    x_groups.append(group)
                
                cindex=[]
        
                for i in range(len(x_groups)):
        
                    temp = []
                    for j in range(len(x_groups)):
                        if i != j:
                            temp.append(x_groups[j])
                    #train = train data(ë“±ë¶„í•œ ê²ƒ ì¤‘ 1ê°œë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€)
                    train=pd.concat(temp)
        
                    #validation = validation data(ë“±ë¶„í•œ ê²ƒ ì¤‘ 1ê°œ)
                    validation = x_groups[i]
        
                    train_target=train[['Status','OS']]
                    test_target=validation[['Status','OS']]
        
                    train_y=prepare_response_variable(train_target)
                    test_y=prepare_response_variable(test_target)
                    #dataì •ì˜ -> train, validation, train_y, test_y
        
                    result = C_index_fastKernelSurvivalSVM(train, train_y, validation, test_y, param_grid, keywords = ['Age'], drop=False, coef_drop=None)
                
                    cindex.append(result[1])
                    #print(result[1]) #ìƒëµ ê°€ëŠ¥
        
                #best_cindex : ì„ íƒëœ ë³€ìˆ˜ë³„ ëª¨ë“  validation cindexê°’ì„ listë¡œ ì €ì¥
                best_cindex.append(np.mean(cindex))
        
        		#max_num : best cindexì˜ ë¦¬ìŠ¤íŠ¸ ë²ˆí˜¸
        	   max_num = best_cindex.index(max(best_cindex))
        
        	   #train_column : best cindexì˜ ì„ íƒëœ ë³€ìˆ˜
        	   train_column = column_groups[max_num].columns
            
        	   remaining_variable = remaining_variable.append({"variable": list(train_column)}, ignore_index = True)
        ```
        

### ğŸ’ªğŸ»Beomseok