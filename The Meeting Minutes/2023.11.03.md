# 2023.11.03

## <Collaborative Work>

### 🌟Collaborative

기존 방법

- train, test split을 100번 반복
- 최종 결과는 앞서 나온 결과 100개의 mean으로 표시

새로운 방법

- split된 train, test data에서 train data를 cross validation진행
    - train data를 5등분 하여 그중 4개로 model select, 나머지 1개로 validation data
    - 이때 5등분 각각 한번씩 validation data로 사용해서 다섯번 진행
    - 다섯번 진행한 결과를 평균내서 best c-index 추출
    
    ```python
    # Create kernel using x_train
    train_kernel, coef, coef_drop, remaining_variables = new_kernel(x_train, drop=False, keywords = ['Age','Sex'])
    
    # Grid Optimization
    kssvm = FastKernelSurvivalSVM(optimizer = "rbtree", kernel = 'precomputed', max_iter = 1000, tol = 1e-6, random_state=36)
    kgcv = GridSearchCV(kssvm, param_grid, n_jobs=-1, refit=True, cv=KFold(n_splits = 5, shuffle=True, random_state=36))
    
    # Fit model
    kgcv.fit(train_kernel, y_train)
    
    # Optimal hyperparameters and c_index
    best_params = kgcv.best_params_
    best_c_index = kgcv.best_score_
    
    # Predict on x_train and calculate c_index
    train_pred = kgcv.predict(train_kernel)
    train_c_index = concordance_index_censored(y_train["Status"], y_train["OS"], train_pred)
    
    # Predict on x_test and calculate c_index
    test_kernel, _, _, _ = new_kernel(x_train, x_test, coef=coef, drop=False, coef_drop=coef_drop, keywords=['Age', 'Sex'])
    test_pred = kgcv.predict(test_kernel)
    test_c_index = concordance_index_censored(y_test["Status"], y_test["OS"], test_pred)
    ```
    
    위의 코드를 다섯번 진행하게 되는데, 이때 x_train에 train data중 5분의 4를 대입하고, x_test에 validation data를 대입
    
- 변수를 1개부터 전체 다 사용하는 경우 모두 확인
    - 예를들어 변수 p가 13개의 경우, p=1~13까지 모두 진행
    - p=1은 변수가 1개인 경우, 즉 13번 진행하게 됨
    - 이때 가장 best c-index를 찾고 그때의 변수를 확인
- 위의 과정을 100번 반복 후 c-index의 평균 확인